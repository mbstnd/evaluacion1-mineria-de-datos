# 1Ô∏è‚É£ Importaci√≥n de librer√≠as principales
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

# 2Ô∏è‚É£ Cargar y exploracion de los datos
df = pd.read_csv(r'c:/workspace/01-mineria-de-datos/StudentsPerformance.csv')
print("\n üìè Dimensiones del dataset:", df.shape)
print("\n üìä Tipos de datos por columna:\n", df.dtypes)
print("\n üßæ Primeras filas del dataset:\n", df.head())

# 3Ô∏è‚É£ Detecci√≥n de valores faltantes

missing_values = df.isnull().sum()
print('\n Valores faltantes por columna:\n', missing_values)

###
# Tras aplicar df.isnull().sum(), se observa que no existen valores faltantes
# en ninguna columna del dataset.
# Esto significa que no es necesario realizar imputaciones ni eliminar registros.
###
# 4Ô∏è‚É£ Transformacion de datos categ√≥ricos ( female = 0, male = 1 )

# Verificar la columna de g√©nero 'y su distribuci√≥n
print("\n üîç An√°lisis de la columna 'gender' (g√©nero):")
print(f"  Valores √∫nicos: {df['gender'].unique()}")

df['gender_encoded'] = df['gender'].map({'female': 0, 'male': 1})



# Mostrar el mapeo realizado
print("\n‚úÖ Transformaci√≥n aplicada:")
print(f"  {df['gender'].unique()[0]} ‚Üí {df['gender_encoded'].unique()[0]}")
print(f"  {df['gender'].unique()[1]} ‚Üí {df['gender_encoded'].unique()[1]}")

# Verificar el resultado
print("\nüìä Comparaci√≥n antes y despu√©s:")
comparison = pd.DataFrame({
      'gender_original': df['gender'].head(10),
      'gender_encoded': df['gender_encoded'].head(10)
  })
print(comparison)


# 5Ô∏è‚É£ Normalizaci√≥n de datos con Min-Max Scaling

# Columnas de puntajes a normalizar
score_columns = ['math score', 'reading score', 'writing score']
print("\n üìä An√°lisis ANTES de la normalizaci√≥n:")
print("="*60)
for col in score_columns:
     print(f"\n{col}:")
     print(f"  Rango original: [{df[col].min()}, {df[col].max()}]")
     print(f"  Media: {df[col].mean():.2f}")
     print(f"  Desviaci√≥n est√°ndar: {df[col].std():.2f}")

# Mostrar primeras filas originales
print("\nüîç Primeras 5 filas - Valores originales:")
print(df[score_columns].head(5))

# Aplicar Min-Max Scaling
scaler = MinMaxScaler()
df_normalized = df.copy()
df_normalized[score_columns] = scaler.fit_transform(df[score_columns])

# Mostrar datos post min max scaling
range_after = df_normalized[score_columns].agg(['min', 'max']).T
print("\n" + "="*60)
print("‚úÖ Normalizaci√≥n aplicada con Min-Max Scaling")
print("="*60)

print("\nüìä Rango de valores tras Min-Max Scaling:")
for col in score_columns:
    print(f"  {col}: min = {df_normalized[col].min():.2f}, max = {df_normalized[col].max():.2f}")


# 6Ô∏è‚É£ Detecci√≥n de valores at√≠picos
print("\nüîç Detecci√≥n de valores at√≠picos:")
print("=" * 60)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df[score_columns], palette="Set3")
plt.title('Boxplot de Puntajes de Estudiantes')
plt.ylabel('Puntaje')
plt.xlabel('Per√≠odo')
plt.grid(True, alpha=0.3)
plt.show()

# Identificaci√≥n de outliers usando el m√©todo del IQR

print("\nüìà Identificaci√≥n de outliers mediante el m√©todo del IQR:")
print("=" * 60)

def detected_outliers_iqr(series):
    """
    Detecta valores at√≠picos (outliers) en una serie num√©rica usando el m√©todo del IQR.
    Par√°metros:
        series (pd.Series): columna num√©rica del DataFrame
    Retorna:
        outliers (pd.Series): valores considerados como at√≠picos
    """
    # Calcular cuartiles
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1

    # Calcular l√≠mites
    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR

    # Filtrar los valores fuera del rango
    outliers = series[(series < lower_limit) | (series > upper_limit)]

    print(f"üìä Columna analizada: {series}")
    print(f" - Q1 (25%): {Q1:.2f}")
    print(f" - Q3 (75%): {Q3:.2f}")
    print(f" - IQR: {IQR:.2f}")
    print(f" - L√≠mite inferior: {lower_limit:.2f}")
    print(f" - L√≠mite superior: {upper_limit:.2f}")
    print(f" - Cantidad de outliers: {len(outliers)}\n")

    return outliers

for col in score_columns:
    outliers = detected_outliers_iqr(df[col])
    if not outliers.empty:
        print(f"üî∏ Outliers encontrados en {col}: {list(outliers.values)}\n")
    else:
        print(f"‚úÖ No se detectaron outliers en {col}.\n")



# 7Ô∏è‚É£ An√°lisis de componentes principales (PCA)
print("\nüîç An√°lisis de Componentes Principales (PCA):")
print("=" * 60)

# Selecci√≥n de caracter√≠sticas num√©ricas
numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
print(f"üî∏ Caracter√≠sticas num√©ricas seleccionadas para PCA: {numeric_features}")

# Estandarizaci√≥n de los datos
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[numeric_features])

# Aplicaci√≥n de PCA con 2 componentes
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df_scaled)

# Resultados del PCA
print("\n‚úÖ PCA aplicado con √©xito.")
print(f"üî∏ Varianza explicada por cada componente: {pca.explained_variance_ratio_}")
print(f"üîπ Varianza total explicada: {np.sum(pca.explained_variance_ratio_) * 100:.2f}%")

# Crear categor√≠as basadas en el promedio de las tres calificaciones
df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)
df['performance_category'] = pd.qcut(df['average_score'], q=3, labels=['Bajo', 'Medio', 'Alto'])

# DataFrame con resultados y categor√≠a
pca_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])
pca_df['Rendimiento'] = df['performance_category']

# Visualizaci√≥n de los resultados
plt.figure(figsize=(10, 6))
sns.scatterplot(x='PCA1', y='PCA2', data=pca_df, hue='Rendimiento', palette="Set2")
plt.title('PCA de Caracter√≠sticas Num√©ricas por Nivel de Rendimiento')
plt.xlabel('Primer Componente Principal')
plt.ylabel('Segundo Componente Principal')
plt.grid(True, alpha=0.3)
plt.legend(title='Nivel de Rendimiento')
plt.show()